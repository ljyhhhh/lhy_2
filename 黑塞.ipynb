{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf746f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\pytorch\\lib\\site-packages\\gdown\\cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ym6G7KKNkbsqSnMmnxdQKHO1JBoF0LPR\n",
      "To: C:\\Users\\dell\\data.pth\n",
      "\n",
      "  0%|          | 0.00/34.5k [00:00<?, ?B/s]\n",
      "100%|██████████| 34.5k/34.5k [00:00<00:00, 163kB/s]\n",
      "100%|██████████| 34.5k/34.5k [00:00<00:00, 155kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient norm: 0.0003472121352388058, minimum ratio: 0.4296875\n"
     ]
    }
   ],
   "source": [
    "student_id = '1234567' # fill with your student ID\n",
    "\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from collections import defaultdict\n",
    "from autograd_lib import autograd_lib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class MathRegressor(nn.Module):\n",
    "    def __init__(self, num_hidden=128):\n",
    "        super().__init__()\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(1, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.regressor(x)\n",
    "        return x\n",
    "    #\n",
    "!gdown --id 1ym6G7KKNkbsqSnMmnxdQKHO1JBoF0LPR\n",
    "\n",
    "# find the key from student_id\n",
    "import re\n",
    "\n",
    "key = student_id[-1]\n",
    "if re.match('[0-9]', key) is not None:\n",
    "    key = int(key)\n",
    "else:\n",
    "    key = ord(key) % 10\n",
    "     \n",
    "\n",
    "# load checkpoint and data corresponding to the key\n",
    "model = MathRegressor()\n",
    "autograd_lib.register(model)\n",
    "\n",
    "data = torch.load('data.pth')[key]\n",
    "model.load_state_dict(data['model'])\n",
    "train, target = data['data']\n",
    "\n",
    "# function to compute gradient norm\n",
    "def compute_gradient_norm(model, criterion, train, target):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    output = model(train)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "\n",
    "    grads = []\n",
    "    for p in model.regressor.children():\n",
    "        if isinstance(p, nn.Linear):\n",
    "            param_norm = p.weight.grad.norm(2).item()\n",
    "            grads.append(param_norm)\n",
    "\n",
    "    grad_mean = np.mean(grads) # compute mean of gradient norms\n",
    "\n",
    "    return grad_mean\n",
    "\n",
    "# source code from the official document https://github.com/cybertronai/autograd-lib\n",
    "\n",
    "# helper function to save activations\n",
    "def save_activations(layer, A, _):\n",
    "    '''\n",
    "    A is the input of the layer, we use batch size of 6 here\n",
    "    layer 1: A has size of (6, 1)\n",
    "    layer 2: A has size of (6, 128)\n",
    "    '''\n",
    "    activations[layer] = A\n",
    "\n",
    "# helper function to compute Hessian matrix\n",
    "def compute_hess(layer, _, B):\n",
    "    '''\n",
    "    B is the backprop value of the layer\n",
    "    layer 1: B has size of (6, 128)\n",
    "    layer 2: B ahs size of (6, 1)\n",
    "    '''\n",
    "    A = activations[layer]\n",
    "    BA = torch.einsum('nl,ni->nli', B, A) # do batch-wise outer product\n",
    "\n",
    "    # full Hessian\n",
    "    hess[layer] += torch.einsum('nli,nkj->likj', BA, BA) # do batch-wise outer product, then sum over the batch\n",
    "     \n",
    "\n",
    "# function to compute the minimum ratio\n",
    "def compute_minimum_ratio(model, criterion, train, target):\n",
    "    model.zero_grad()\n",
    "    # compute Hessian matrix\n",
    "    # save the gradient of each layer\n",
    "    with autograd_lib.module_hook(save_activations):\n",
    "        output = model(train)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "    # compute Hessian according to the gradient value stored in the previous step\n",
    "    with autograd_lib.module_hook(compute_hess):\n",
    "        autograd_lib.backward_hessian(output, loss='LeastSquares')\n",
    "\n",
    "    layer_hess = list(hess.values())\n",
    "    minimum_ratio = []\n",
    "\n",
    "    # compute eigenvalues of the Hessian matrix\n",
    "    for h in layer_hess:\n",
    "        size = h.shape[0] * h.shape[1]\n",
    "        h = h.reshape(size, size)\n",
    "        h_eig = torch.symeig(h).eigenvalues # torch.symeig() returns eigenvalues and eigenvectors of a real symmetric matrix\n",
    "        num_greater = torch.sum(h_eig > 0).item()\n",
    "        minimum_ratio.append(num_greater / len(h_eig))\n",
    "\n",
    "    ratio_mean = np.mean(minimum_ratio) # compute mean of minimum ratio\n",
    "\n",
    "    return ratio_mean\n",
    "\n",
    "\n",
    "\n",
    "# the main function to compute gradient norm and minimum ratio\n",
    "def main(model, train, target):\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    gradient_norm = compute_gradient_norm(model, criterion, train, target)\n",
    "    minimum_ratio = compute_minimum_ratio(model, criterion, train, target)\n",
    "\n",
    "    print('gradient norm: {}, minimum ratio: {}'.format(gradient_norm, minimum_ratio))\n",
    "    if()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # fix random seed\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # reset compute dictionaries\n",
    "    activations = defaultdict(int)\n",
    "    hess = defaultdict(float)\n",
    "\n",
    "    # compute Hessian\n",
    "    main(model, train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea098d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
